{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "precise-studio",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from openfl.experimental.interface import FLSpec, Aggregator, Collaborator\n",
    "from openfl.experimental.runtime import LocalRuntime\n",
    "from openfl.experimental.placement import aggregator, collaborator\n",
    "\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST('files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST('files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "def FedAvg(models):\n",
    "    new_model = models[0]\n",
    "    state_dicts = [model.state_dict() for model in models]\n",
    "    state_dict = new_model.state_dict()\n",
    "    for key in models[1].state_dict():\n",
    "        state_dict[key] = np.sum([state[key] for state in state_dicts],axis=0) / len(models)\n",
    "    new_model.load_state_dict(state_dict)\n",
    "    return new_model\n",
    "\n",
    "def inference(network,test_loader):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      for data, target in test_loader:\n",
    "        output = network(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "      test_loss, correct, len(test_loader.dataset),\n",
    "      100. * correct / len(test_loader.dataset)))\n",
    "    accuracy = float(correct / len(test_loader.dataset))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "difficult-madrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator step \"start\" registered\n",
      "Collaborator step \"aggregated_model_validation\" registered\n",
      "Collaborator step \"train\" registered\n",
      "Collaborator step \"local_model_validation\" registered\n",
      "Aggregator step \"join\" registered\n",
      "Aggregator step \"end\" registered\n"
     ]
    }
   ],
   "source": [
    "class FederatedFlow(FLSpec):\n",
    "\n",
    "    def __init__(self, model = None, optimizer = None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate,\n",
    "                                   momentum=momentum)\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        print(f'Performing initialization for model')\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        self.private = 10\n",
    "        self.next(self.aggregated_model_validation,foreach='collaborators',exclude=['private'])\n",
    "\n",
    "    @collaborator\n",
    "    def aggregated_model_validation(self):\n",
    "        print(f'Performing aggregated model validation for collaborator {self.input}')\n",
    "        self.agg_validation_score = inference(self.model,self.test_loader)\n",
    "        print(f'{self.input} value of {self.agg_validation_score}')\n",
    "        self.next(self.train)\n",
    "\n",
    "    @collaborator\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        train_losses = []\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "          self.optimizer.zero_grad()\n",
    "          output = self.model(data)\n",
    "          loss = F.nll_loss(output, target)\n",
    "          loss.backward()\n",
    "          self.optimizer.step()\n",
    "          if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: 1 [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "               batch_idx * len(data), len(self.train_loader.dataset),\n",
    "              100. * batch_idx / len(self.train_loader), loss.item()))\n",
    "            self.loss = loss.item()\n",
    "            torch.save(self.model.state_dict(), 'model.pth')\n",
    "            torch.save(self.optimizer.state_dict(), 'optimizer.pth')\n",
    "        self.training_completed = True\n",
    "        self.next(self.local_model_validation)\n",
    "\n",
    "    @collaborator\n",
    "    def local_model_validation(self):\n",
    "        self.local_validation_score = inference(self.model,self.test_loader)\n",
    "        print(f'Doing local model validation for collaborator {self.input}: {self.local_validation_score}')\n",
    "        self.next(self.join, exclude=['training_completed'])\n",
    "\n",
    "    @aggregator\n",
    "    def join(self,inputs):\n",
    "        self.average_loss = sum(input.loss for input in inputs)/len(inputs)\n",
    "        self.aggregated_model_accuracy = sum(input.agg_validation_score for input in inputs)/len(inputs)\n",
    "        self.local_model_accuracy = sum(input.local_validation_score for input in inputs)/len(inputs)\n",
    "        print(f'Average aggregated model validation values = {self.aggregated_model_accuracy}')\n",
    "        print(f'Average training loss = {self.average_loss}')\n",
    "        print(f'Average local model validation values = {self.local_model_accuracy}')\n",
    "        self.model = FedAvg([input.model for input in inputs])\n",
    "        self.optimizer = [input.optimizer for input in inputs][0]\n",
    "        self.next(self.end)\n",
    "        \n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        print(f'This is the end of the flow')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forward-world",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local runtime collaborators = {'Portland': <openfl.experimental.interface.participants.Collaborator object at 0x7f4f9c25dc40>, 'Seattle': <openfl.experimental.interface.participants.Collaborator object at 0x7f4f9c25db50>, 'Chandler': <openfl.experimental.interface.participants.Collaborator object at 0x7f4f9c25dc70>, 'Bangalore': <openfl.experimental.interface.participants.Collaborator object at 0x7f4f9c25dd00>}\n",
      "Starting round 0...\n",
      "Created flow FederatedFlow\n",
      "\n",
      "Calling start\n",
      "Performing initialization for model\n",
      "Saving data artifacts for start\n",
      "TaskDataStore init function invoked!\n",
      "Saved data artifacts for start\n",
      "Sending state from aggregator to collaborators\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Running aggregated_model_validation in a new process\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Calling aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Performing aggregated model validation for collaborator Portland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m /home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m   warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Test set: Avg. loss: 2.3264, Accuracy: 309/2500 (12%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Portland value of 0.12359999865293503\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saving data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Running aggregated_model_validation in a new process\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Calling aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Performing aggregated model validation for collaborator Seattle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m /home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m   warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Test set: Avg. loss: 2.3319, Accuracy: 272/2500 (11%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Seattle value of 0.1088000014424324\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saving data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m TaskDataStore init function invoked!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m /home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m   warnings.warn(warning.format(ret))\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Running aggregated_model_validation in a new process\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Calling aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Performing aggregated model validation for collaborator Chandler\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saved data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Calling train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [0/15000 (0%)]\tLoss: 2.355470\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [640/15000 (4%)]\tLoss: 2.288348\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [1280/15000 (9%)]\tLoss: 2.310263\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Test set: Avg. loss: 2.3338, Accuracy: 284/2500 (11%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Chandler value of 0.1136000007390976\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saving data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [1920/15000 (13%)]\tLoss: 2.294840\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [2560/15000 (17%)]\tLoss: 2.277605\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Running aggregated_model_validation in a new process\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Calling aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Performing aggregated model validation for collaborator Bangalore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m /home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m   warnings.warn(warning.format(ret))\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [3200/15000 (21%)]\tLoss: 2.262601\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saved data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Calling train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [0/15000 (0%)]\tLoss: 2.317851\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [3840/15000 (26%)]\tLoss: 2.230582\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [640/15000 (4%)]\tLoss: 2.343905\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [1280/15000 (9%)]\tLoss: 2.282692\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [4480/15000 (30%)]\tLoss: 2.158489\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Test set: Avg. loss: 2.3345, Accuracy: 272/2500 (11%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Bangalore value of 0.1088000014424324\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [1920/15000 (13%)]\tLoss: 2.326989\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saving data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [5120/15000 (34%)]\tLoss: 2.174633\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [2560/15000 (17%)]\tLoss: 2.215069\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [5760/15000 (38%)]\tLoss: 2.044475\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [3200/15000 (21%)]\tLoss: 2.279601\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [6400/15000 (43%)]\tLoss: 2.031337\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saved data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Calling train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [3840/15000 (26%)]\tLoss: 2.170111\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [0/15000 (0%)]\tLoss: 2.327266\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [7040/15000 (47%)]\tLoss: 2.031010\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [4480/15000 (30%)]\tLoss: 2.139125\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [640/15000 (4%)]\tLoss: 2.320790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [7680/15000 (51%)]\tLoss: 1.663228\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [5120/15000 (34%)]\tLoss: 1.938834\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [1280/15000 (9%)]\tLoss: 2.295260\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [1920/15000 (13%)]\tLoss: 2.263805\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [8320/15000 (55%)]\tLoss: 1.665153\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [5760/15000 (38%)]\tLoss: 1.838812\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [6400/15000 (43%)]\tLoss: 1.864763\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [2560/15000 (17%)]\tLoss: 2.255345\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [8960/15000 (60%)]\tLoss: 1.775899\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [9600/15000 (64%)]\tLoss: 1.625261\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [7040/15000 (47%)]\tLoss: 1.684331\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [3200/15000 (21%)]\tLoss: 2.225609\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [3840/15000 (26%)]\tLoss: 2.184451\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saved data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Calling train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [0/15000 (0%)]\tLoss: 2.387879\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [10240/15000 (68%)]\tLoss: 1.452844\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [7680/15000 (51%)]\tLoss: 1.693966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [8320/15000 (55%)]\tLoss: 1.547360\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [4480/15000 (30%)]\tLoss: 2.155389\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [640/15000 (4%)]\tLoss: 2.305840\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [10880/15000 (72%)]\tLoss: 1.574975\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [1280/15000 (9%)]\tLoss: 2.275250\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [8960/15000 (60%)]\tLoss: 1.278011\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [5120/15000 (34%)]\tLoss: 2.088869\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [11520/15000 (77%)]\tLoss: 1.367519\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [9600/15000 (64%)]\tLoss: 1.275976\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [5760/15000 (38%)]\tLoss: 1.963856\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [1920/15000 (13%)]\tLoss: 2.241651\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [12160/15000 (81%)]\tLoss: 1.615099\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [10240/15000 (68%)]\tLoss: 1.314974\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [6400/15000 (43%)]\tLoss: 1.927705\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [2560/15000 (17%)]\tLoss: 2.203657\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [3200/15000 (21%)]\tLoss: 2.191882\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [12800/15000 (85%)]\tLoss: 1.172763\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [10880/15000 (72%)]\tLoss: 1.203996\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [7040/15000 (47%)]\tLoss: 1.960440\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [7680/15000 (51%)]\tLoss: 1.896483\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [3840/15000 (26%)]\tLoss: 2.184890\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [13440/15000 (89%)]\tLoss: 1.129359\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [11520/15000 (77%)]\tLoss: 1.285566\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [14080/15000 (94%)]\tLoss: 0.977744\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [12160/15000 (81%)]\tLoss: 1.026859\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [8320/15000 (55%)]\tLoss: 1.739099\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [4480/15000 (30%)]\tLoss: 2.129562\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [8960/15000 (60%)]\tLoss: 1.615128\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [5120/15000 (34%)]\tLoss: 1.982381\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [14720/15000 (98%)]\tLoss: 0.899177\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [12800/15000 (85%)]\tLoss: 1.207469\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saving data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [13440/15000 (89%)]\tLoss: 1.079172\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [9600/15000 (64%)]\tLoss: 1.653756\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [5760/15000 (38%)]\tLoss: 2.014320\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [14080/15000 (94%)]\tLoss: 0.998044\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [10240/15000 (68%)]\tLoss: 1.647651\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [6400/15000 (43%)]\tLoss: 1.942972\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saved data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Calling local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [10880/15000 (72%)]\tLoss: 1.471139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m /home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m   warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [14720/15000 (98%)]\tLoss: 0.774632\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saving data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [7040/15000 (47%)]\tLoss: 1.657060\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [11520/15000 (77%)]\tLoss: 1.543556\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [7680/15000 (51%)]\tLoss: 1.596563\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [12160/15000 (81%)]\tLoss: 1.475805\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [8320/15000 (55%)]\tLoss: 1.501449\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saved data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Calling local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [12800/15000 (85%)]\tLoss: 1.367396\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Test set: Avg. loss: 0.6976, Accuracy: 2014/2500 (81%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Doing local model validation for collaborator Portland: 0.8055999875068665\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saving data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m TaskDataStore init function invoked!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m /home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m   warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [8960/15000 (60%)]\tLoss: 1.337309\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [13440/15000 (89%)]\tLoss: 1.264784\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [9600/15000 (64%)]\tLoss: 1.324787\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [14080/15000 (94%)]\tLoss: 1.092788\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saved data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Should transfer from local_model_validation to join\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Test set: Avg. loss: 0.6159, Accuracy: 2092/2500 (84%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Doing local model validation for collaborator Seattle: 0.8367999792098999\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saving data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [10240/15000 (68%)]\tLoss: 1.246044\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [14720/15000 (98%)]\tLoss: 0.957826\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [10880/15000 (72%)]\tLoss: 1.202827\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saving data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saved data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Should transfer from local_model_validation to join\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [11520/15000 (77%)]\tLoss: 0.990688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m /home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m   warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saved data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Calling local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [12160/15000 (81%)]\tLoss: 0.937870\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [12800/15000 (85%)]\tLoss: 1.274359\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [13440/15000 (89%)]\tLoss: 0.994695\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Test set: Avg. loss: 0.7163, Accuracy: 2027/2500 (81%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Doing local model validation for collaborator Chandler: 0.8108000159263611\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saving data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [14080/15000 (94%)]\tLoss: 0.990951\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [14720/15000 (98%)]\tLoss: 0.840520\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saving data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saved data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Should transfer from local_model_validation to join\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m /home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m   warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saved data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Calling local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Test set: Avg. loss: 0.5898, Accuracy: 2106/2500 (84%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Doing local model validation for collaborator Bangalore: 0.8424000144004822\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saving data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saved data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Should transfer from local_model_validation to join\n",
      "Next function = join\n",
      "\n",
      "Calling join\n",
      "Average aggregated model validation values = 0.11370000056922436\n",
      "Average training loss = 0.8680389523506165\n",
      "Average local model validation values = 0.8238999992609024\n",
      "Saving data artifacts for join\n",
      "TaskDataStore init function invoked!\n",
      "Saved data artifacts for join\n",
      "\n",
      "Calling end\n",
      "This is the end of the flow\n",
      "Accuracy improved to 0.11370000056922436 for round 0\n",
      "Starting round 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/pfoley1/anaconda3/envs/federatedflow/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created flow FederatedFlow\n",
      "\n",
      "Calling start\n",
      "Performing initialization for model\n",
      "Saving data artifacts for start\n",
      "TaskDataStore init function invoked!\n",
      "Saved data artifacts for start\n",
      "Sending state from aggregator to collaborators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Running aggregated_model_validation in a new process\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Calling aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Performing aggregated model validation for collaborator Portland\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Test set: Avg. loss: 0.6733, Accuracy: 2117/2500 (85%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Portland value of 0.8468000292778015\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saving data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m TaskDataStore init function invoked!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Running aggregated_model_validation in a new process\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Calling aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Performing aggregated model validation for collaborator Seattle\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Test set: Avg. loss: 0.6750, Accuracy: 2127/2500 (85%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Seattle value of 0.8507999777793884\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saving data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Running aggregated_model_validation in a new process\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Calling aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Performing aggregated model validation for collaborator Chandler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saved data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Calling train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [0/15000 (0%)]\tLoss: 1.105674\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Test set: Avg. loss: 0.6856, Accuracy: 2101/2500 (84%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Chandler value of 0.840399980545044\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [640/15000 (4%)]\tLoss: 1.115932\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saving data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [1280/15000 (9%)]\tLoss: 1.055378\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [1920/15000 (13%)]\tLoss: 0.970920\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saved data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Calling train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [0/15000 (0%)]\tLoss: 0.784710\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [2560/15000 (17%)]\tLoss: 0.765642\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [640/15000 (4%)]\tLoss: 0.855057\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [3200/15000 (21%)]\tLoss: 1.030986\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [1280/15000 (9%)]\tLoss: 0.681836\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Running aggregated_model_validation in a new process\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Calling aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Performing aggregated model validation for collaborator Bangalore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m /tmp/ipykernel_1465/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [1920/15000 (13%)]\tLoss: 0.883527\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [3840/15000 (26%)]\tLoss: 0.885782\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [2560/15000 (17%)]\tLoss: 0.962903\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [4480/15000 (30%)]\tLoss: 0.983388\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Test set: Avg. loss: 0.6671, Accuracy: 2121/2500 (85%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Bangalore value of 0.8483999967575073\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saving data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [3200/15000 (21%)]\tLoss: 0.932804\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [5120/15000 (34%)]\tLoss: 0.938195\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saved data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Calling train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [3840/15000 (26%)]\tLoss: 0.629082\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [5760/15000 (38%)]\tLoss: 0.639480\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [0/15000 (0%)]\tLoss: 1.275314\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [4480/15000 (30%)]\tLoss: 0.871470\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [640/15000 (4%)]\tLoss: 1.005726\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [6400/15000 (43%)]\tLoss: 1.067462\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [5120/15000 (34%)]\tLoss: 0.668869\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [1280/15000 (9%)]\tLoss: 1.186148\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [7040/15000 (47%)]\tLoss: 0.826190\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [1920/15000 (13%)]\tLoss: 0.929209\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [5760/15000 (38%)]\tLoss: 0.577361\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [6400/15000 (43%)]\tLoss: 0.664220\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [7680/15000 (51%)]\tLoss: 0.527074\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [2560/15000 (17%)]\tLoss: 0.924957\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [8320/15000 (55%)]\tLoss: 0.726633\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [3200/15000 (21%)]\tLoss: 0.949141\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [7040/15000 (47%)]\tLoss: 0.657281\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [7680/15000 (51%)]\tLoss: 0.440556\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [8960/15000 (60%)]\tLoss: 0.779350\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [3840/15000 (26%)]\tLoss: 0.981819\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [8320/15000 (55%)]\tLoss: 0.588710\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [9600/15000 (64%)]\tLoss: 0.899717\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [4480/15000 (30%)]\tLoss: 1.027405\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saved data artifacts for aggregated_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Calling train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [0/15000 (0%)]\tLoss: 1.002910\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [8960/15000 (60%)]\tLoss: 0.692673\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [10240/15000 (68%)]\tLoss: 0.814489\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [5120/15000 (34%)]\tLoss: 0.713909\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [640/15000 (4%)]\tLoss: 0.762462\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [9600/15000 (64%)]\tLoss: 0.700774\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [10880/15000 (72%)]\tLoss: 0.746171\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [1280/15000 (9%)]\tLoss: 0.638923\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [5760/15000 (38%)]\tLoss: 0.743634\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [6400/15000 (43%)]\tLoss: 1.020739\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [10240/15000 (68%)]\tLoss: 0.604540\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [11520/15000 (77%)]\tLoss: 0.692782\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [1920/15000 (13%)]\tLoss: 0.749757\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [10880/15000 (72%)]\tLoss: 0.513386\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [12160/15000 (81%)]\tLoss: 0.678462\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [7040/15000 (47%)]\tLoss: 0.959437\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [2560/15000 (17%)]\tLoss: 0.874047\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [7680/15000 (51%)]\tLoss: 0.836066\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [11520/15000 (77%)]\tLoss: 0.696834\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [12800/15000 (85%)]\tLoss: 0.787860\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [3200/15000 (21%)]\tLoss: 0.883610\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [12160/15000 (81%)]\tLoss: 0.825423\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [13440/15000 (89%)]\tLoss: 0.783008\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [8320/15000 (55%)]\tLoss: 0.961947\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [3840/15000 (26%)]\tLoss: 0.792419\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [8960/15000 (60%)]\tLoss: 0.826969\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [12800/15000 (85%)]\tLoss: 0.560694\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [14080/15000 (94%)]\tLoss: 0.714328\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [4480/15000 (30%)]\tLoss: 0.651197\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [9600/15000 (64%)]\tLoss: 0.814124\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [13440/15000 (89%)]\tLoss: 0.676234\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Train Epoch: 1 [14720/15000 (98%)]\tLoss: 0.739641\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saving data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [5120/15000 (34%)]\tLoss: 0.720135\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [14080/15000 (94%)]\tLoss: 0.596601\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [10240/15000 (68%)]\tLoss: 0.666659\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [5760/15000 (38%)]\tLoss: 0.690690\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [10880/15000 (72%)]\tLoss: 0.876575\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Train Epoch: 1 [14720/15000 (98%)]\tLoss: 0.677698\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saving data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [6400/15000 (43%)]\tLoss: 0.589659\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saved data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Calling local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [11520/15000 (77%)]\tLoss: 0.658908\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [7040/15000 (47%)]\tLoss: 0.710271\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [12160/15000 (81%)]\tLoss: 0.697214\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saved data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Calling local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [7680/15000 (51%)]\tLoss: 0.563131\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [12800/15000 (85%)]\tLoss: 0.897218\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Test set: Avg. loss: 0.3680, Accuracy: 2230/2500 (89%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Doing local model validation for collaborator Portland: 0.8920000195503235\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saving data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [8320/15000 (55%)]\tLoss: 0.594320\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [13440/15000 (89%)]\tLoss: 0.636636\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [8960/15000 (60%)]\tLoss: 0.518836\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [14080/15000 (94%)]\tLoss: 0.879729\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Test set: Avg. loss: 0.3889, Accuracy: 2215/2500 (89%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Doing local model validation for collaborator Seattle: 0.8859999775886536\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saving data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Saved data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1846)\u001b[0m Should transfer from local_model_validation to join\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [9600/15000 (64%)]\tLoss: 0.609882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Train Epoch: 1 [14720/15000 (98%)]\tLoss: 0.473892\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saving data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [10240/15000 (68%)]\tLoss: 0.601058\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Saved data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1850)\u001b[0m Should transfer from local_model_validation to join\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [10880/15000 (72%)]\tLoss: 0.588668\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [11520/15000 (77%)]\tLoss: 0.667979\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saved data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Calling local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [12160/15000 (81%)]\tLoss: 0.641385\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [12800/15000 (85%)]\tLoss: 0.429224\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Test set: Avg. loss: 0.3675, Accuracy: 2229/2500 (89%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Doing local model validation for collaborator Chandler: 0.8916000127792358\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saving data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [13440/15000 (89%)]\tLoss: 0.569381\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [14080/15000 (94%)]\tLoss: 0.406456\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Train Epoch: 1 [14720/15000 (98%)]\tLoss: 0.458939\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Saved data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1816)\u001b[0m Should transfer from local_model_validation to join\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saving data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saved data artifacts for train\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Calling local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Test set: Avg. loss: 0.3455, Accuracy: 2243/2500 (90%)\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m \n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Doing local model validation for collaborator Bangalore: 0.8971999883651733\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saving data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m TaskDataStore init function invoked!\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Saved data artifacts for local_model_validation\n",
      "\u001b[2m\u001b[36m(wrapper pid=1827)\u001b[0m Should transfer from local_model_validation to join\n",
      "Next function = join\n",
      "\n",
      "Calling join\n",
      "Average aggregated model validation values = 0.8465999960899353\n",
      "Average training loss = 0.5875426530838013\n",
      "Average local model validation values = 0.8916999995708466\n",
      "Saving data artifacts for join\n",
      "TaskDataStore init function invoked!\n",
      "Saved data artifacts for join\n",
      "\n",
      "Calling end\n",
      "This is the end of the flow\n",
      "Accuracy improved to 0.8465999960899353 for round 1\n"
     ]
    }
   ],
   "source": [
    "# Setup participants\n",
    "aggregator = Aggregator()\n",
    "aggregator.private_attributes = {}\n",
    "\n",
    "# Setup collaborators with private attributes\n",
    "collaborator_names = ['Portland', 'Seattle', 'Chandler','Bangalore']\n",
    "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
    "for idx, collaborator in enumerate(collaborators):\n",
    "    local_train = deepcopy(mnist_train)\n",
    "    local_test = deepcopy(mnist_test)\n",
    "    local_train.data = mnist_train.data[idx::len(collaborators)]\n",
    "    local_train.targets = mnist_train.targets[idx::len(collaborators)]\n",
    "    local_test.data = mnist_test.data[idx::len(collaborators)]\n",
    "    local_test.targets = mnist_test.targets[idx::len(collaborators)]\n",
    "    collaborator.private_attributes = {\n",
    "            'train_loader': torch.utils.data.DataLoader(local_train,batch_size=batch_size_train, shuffle=True),\n",
    "            'test_loader': torch.utils.data.DataLoader(local_test,batch_size=batch_size_train, shuffle=True)\n",
    "    }\n",
    "\n",
    "local_runtime = LocalRuntime(aggregator=aggregator, collaborators=collaborators)\n",
    "print(f'Local runtime collaborators = {local_runtime._collaborators}')\n",
    "\n",
    "model = None\n",
    "best_model = None\n",
    "optimizer = None\n",
    "top_model_accuracy = 0\n",
    "for i in range(2):\n",
    "    print(f'Starting round {i}...')\n",
    "    flflow = FederatedFlow(model,optimizer,checkpoint=True)\n",
    "    flflow.runtime = local_runtime\n",
    "    flflow.run()\n",
    "    model = flflow.model\n",
    "    optimizer = flflow.optimizer\n",
    "    aggregated_model_accuracy = flflow.aggregated_model_accuracy\n",
    "    if aggregated_model_accuracy > top_model_accuracy:\n",
    "        print(f'Accuracy improved to {aggregated_model_accuracy} for round {i}')\n",
    "        top_model_accuracy = aggregated_model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verified-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = flflow._run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "composed-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statutory-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Metaflow, Flow, Task, Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifty-tamil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Flow('LinearFlow'),\n",
       " Flow('FederatedFlow'),\n",
       " Flow('VerticalFlow'),\n",
       " Flow('NewFlow'),\n",
       " Flow('BranchFlow'),\n",
       " Flow('TestFlow'),\n",
       " Flow('ForeachFlow')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Metaflow()\n",
    "list(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grand-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Flow('FederatedFlow').latest_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incident-novelty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run('FederatedFlow/1664554700764836')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "increasing-dressing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Step('FederatedFlow/1664554700764836/join'),\n",
       " Step('FederatedFlow/1664554700764836/local_model_validation'),\n",
       " Step('FederatedFlow/1664554700764836/train'),\n",
       " Step('FederatedFlow/1664554700764836/aggregated_model_validation'),\n",
       " Step('FederatedFlow/1664554700764836/start')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "olympic-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Step(f'FederatedFlow/{run_id}/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "awful-posting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Step('FederatedFlow/1664554700764836/train')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "median-double",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Task('FederatedFlow/1664554700764836/train/12'),\n",
       " Task('FederatedFlow/1664554700764836/train/10'),\n",
       " Task('FederatedFlow/1664554700764836/train/7'),\n",
       " Task('FederatedFlow/1664554700764836/train/6')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adult-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Task(f'FederatedFlow/{run_id}/train/12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "changed-hungarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task('FederatedFlow/1664554700764836/train/12')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "academic-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MetaflowData: collaborators, model, agg_validation_score, loss, training_completed, train_loader, input, test_loader, optimizer>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "thermal-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskDataStore init function invoked!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bangalore'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-working",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
