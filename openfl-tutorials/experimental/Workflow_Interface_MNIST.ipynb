{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "precise-studio",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keerti/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from openfl.experimental.interface import FLSpec, Aggregator, Collaborator\n",
    "from openfl.experimental.runtime import LocalRuntime\n",
    "from openfl.experimental.placement import aggregator, collaborator\n",
    "\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST('files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST('files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "def FedAvg(models):\n",
    "    new_model = models[0]\n",
    "    state_dicts = [model.state_dict() for model in models]\n",
    "    state_dict = new_model.state_dict()\n",
    "    for key in models[1].state_dict():\n",
    "        state_dict[key] = np.sum([state[key] for state in state_dicts],axis=0) / len(models)\n",
    "    new_model.load_state_dict(state_dict)\n",
    "    return new_model\n",
    "\n",
    "def inference(network,test_loader):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      for data, target in test_loader:\n",
    "        output = network(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "      test_loss, correct, len(test_loader.dataset),\n",
    "      100. * correct / len(test_loader.dataset)))\n",
    "    accuracy = float(correct / len(test_loader.dataset))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "difficult-madrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator step \"start\" registered\n",
      "Collaborator step \"aggregated_model_validation\" registered\n",
      "Collaborator step \"train\" registered\n",
      "Collaborator step \"local_model_validation\" registered\n",
      "Aggregator step \"join\" registered\n",
      "Aggregator step \"end\" registered\n"
     ]
    }
   ],
   "source": [
    "class FederatedFlow(FLSpec):\n",
    "\n",
    "    def __init__(self, model = None, optimizer = None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate,\n",
    "                                   momentum=momentum)\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Start step.\n",
    "        \"\"\"\n",
    "        print(f'Performing initialization for model')\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        self.private = 10\n",
    "        self.next(self.aggregated_model_validation,foreach='collaborators',exclude=['private'])\n",
    "\n",
    "    @collaborator\n",
    "    def aggregated_model_validation(self):\n",
    "        \"\"\"\n",
    "        Perform Aggregated model validation.\n",
    "        \"\"\"\n",
    "        print(f'Performing aggregated model validation for collaborator {self.input}')\n",
    "        self.agg_validation_score = inference(self.model,self.test_loader)\n",
    "        print(f'{self.input} value of {self.agg_validation_score}')\n",
    "        self.next(self.train)\n",
    "\n",
    "    @collaborator\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Local Model Training.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate,\n",
    "                                   momentum=momentum)\n",
    "        train_losses = []\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "          self.optimizer.zero_grad()\n",
    "          output = self.model(data)\n",
    "          loss = F.nll_loss(output, target)\n",
    "          loss.backward()\n",
    "          self.optimizer.step()\n",
    "          if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: 1 [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "               batch_idx * len(data), len(self.train_loader.dataset),\n",
    "              100. * batch_idx / len(self.train_loader), loss.item()))\n",
    "            self.loss = loss.item()\n",
    "            torch.save(self.model.state_dict(), 'model.pth')\n",
    "            torch.save(self.optimizer.state_dict(), 'optimizer.pth')\n",
    "        self.training_completed = True\n",
    "        self.next(self.local_model_validation)\n",
    "\n",
    "    @collaborator\n",
    "    def local_model_validation(self):\n",
    "        \"\"\"\n",
    "        Local Model Validation.\n",
    "        \"\"\"\n",
    "        self.local_validation_score = inference(self.model,self.test_loader)\n",
    "        print(f'Doing local model validation for collaborator {self.input}: {self.local_validation_score}')\n",
    "        self.next(self.join, exclude=['training_completed'])\n",
    "\n",
    "    @aggregator\n",
    "    def join(self,inputs):\n",
    "        \"\"\"\n",
    "        Model Aggregation.\n",
    "        \"\"\"\n",
    "        self.average_loss = sum(input.loss for input in inputs)/len(inputs)\n",
    "        self.aggregated_model_accuracy = sum(input.agg_validation_score for input in inputs)/len(inputs)\n",
    "        self.local_model_accuracy = sum(input.local_validation_score for input in inputs)/len(inputs)\n",
    "        print(f'Average aggregated model validation values = {self.aggregated_model_accuracy}')\n",
    "        print(f'Average training loss = {self.average_loss}')\n",
    "        print(f'Average local model validation values = {self.local_model_accuracy}')\n",
    "        self.model = FedAvg([input.model for input in inputs])\n",
    "        self.optimizer = [input.optimizer for input in inputs][0]\n",
    "        self.next(self.end)\n",
    "        \n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        End step.\n",
    "        \"\"\"\n",
    "        print(f'This is the end of the flow')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forward-world",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local runtime collaborators = {'Portland': <openfl.experimental.interface.participants.Collaborator object at 0x7fdd61f38310>}\n",
      "Starting round 0...\n",
      "Created flow FederatedFlow\n",
      "\n",
      "Calling start\n",
      "Performing initialization for model\n",
      "Saving data artifacts for start\n",
      "Saved data artifacts for start\n",
      "Sending state from aggregator to collaborators\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "Performing aggregated model validation for collaborator Portland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31890/1561403287.py:53: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "/home/keerti/ls/envs/openfl_github/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3316, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "Portland value of 0.1137000024318695\n",
      "Saving data artifacts for aggregated_model_validation\n",
      "Saved data artifacts for aggregated_model_validation\n",
      "\n",
      "Calling train\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.360446\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.364010\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.329987\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.249067\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.288059\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.218085\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.214215\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.111192\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.092593\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.989863\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.911151\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.659503\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.869479\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.660094\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.577335\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.550470\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.304469\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.408615\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.306857\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.171410\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.161340\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.056438\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.973559\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.988466\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.876379\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.110772\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.848415\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.067798\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.947321\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.951386\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.987387\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.935992\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.903111\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.706188\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.709833\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.879544\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.993489\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.852373\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.922939\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.529357\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.635253\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.811273\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.855730\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.572050\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.708048\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.752296\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.569595\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.451762\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.526607\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.617095\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.586207\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.572290\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.668751\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.484946\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.726332\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.668978\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.544869\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.459296\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.546281\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.582694\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.702953\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.782156\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.483035\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.567936\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.538588\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.701660\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.445924\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.535440\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.650444\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.473018\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.577447\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.456549\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.523148\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.492161\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.629943\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.603842\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.489095\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.587566\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.343006\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.428849\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.853840\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.487633\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.423521\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.484473\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.518829\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.284565\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.495523\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.337892\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.764206\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.414852\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.334114\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.495094\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.543225\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.384769\n",
      "Saving data artifacts for train\n",
      "Saved data artifacts for train\n",
      "\n",
      "Calling local_model_validation\n",
      "\n",
      "Test set: Avg. loss: 0.1995, Accuracy: 9384/10000 (94%)\n",
      "\n",
      "Doing local model validation for collaborator Portland: 0.9383999705314636\n",
      "Saving data artifacts for local_model_validation\n",
      "Saved data artifacts for local_model_validation\n",
      "Should transfer from local_model_validation to join\n",
      "Next function = join\n",
      "\n",
      "Calling join\n",
      "Average aggregated model validation values = 0.1137000024318695\n",
      "Average training loss = 0.3847687244415283\n",
      "Average local model validation values = 0.9383999705314636\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m flflow \u001b[39m=\u001b[39m FederatedFlow(model,optimizer,checkpoint\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m flflow\u001b[39m.\u001b[39mruntime \u001b[39m=\u001b[39m local_runtime\n\u001b[0;32m---> 32\u001b[0m flflow\u001b[39m.\u001b[39mrun()\n\u001b[1;32m     33\u001b[0m model \u001b[39m=\u001b[39m flflow\u001b[39m.\u001b[39mmodel\n\u001b[1;32m     34\u001b[0m optimizer \u001b[39m=\u001b[39m flflow\u001b[39m.\u001b[39moptimizer\n",
      "File \u001b[0;32m~/ls/envs/openfl_github/lib/python3.8/site-packages/openfl/experimental/interface/fl_spec.py:80\u001b[0m, in \u001b[0;36mFLSpec.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[39mraise\u001b[39;00m SerializationException(\u001b[39mstr\u001b[39m(e)\u001b[39m+\u001b[39mmsg)\n\u001b[1;32m     79\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     81\u001b[0m \u001b[39mfor\u001b[39;00m name, attr \u001b[39min\u001b[39;00m final_attributes:\n\u001b[1;32m     82\u001b[0m     \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, name, attr)\n",
      "File \u001b[0;32m~/ls/envs/openfl_github/lib/python3.8/site-packages/openfl/experimental/interface/fl_spec.py:68\u001b[0m, in \u001b[0;36mFLSpec.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCreated flow \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m     69\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcannot pickle\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e) \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mFailed to unpickle\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/ls/envs/openfl_github/lib/python3.8/site-packages/openfl/experimental/placement/placement.py:48\u001b[0m, in \u001b[0;36maggregator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mwith\u001b[39;00m RedirectStdStreamContext() \u001b[39mas\u001b[39;00m context_stream:\n\u001b[1;32m     46\u001b[0m     \u001b[39m# context_stream capture stdout and stderr for the function f.__name__\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[39msetattr\u001b[39m(wrapper, \u001b[39m\"\u001b[39m\u001b[39m_stream_buffer\u001b[39m\u001b[39m\"\u001b[39m, context_stream)\n\u001b[0;32m---> 48\u001b[0m     f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn [3], line 18\u001b[0m, in \u001b[0;36mFederatedFlow.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollaborators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mruntime\u001b[39m.\u001b[39mcollaborators\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprivate \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregated_model_validation,foreach\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcollaborators\u001b[39;49m\u001b[39m'\u001b[39;49m,exclude\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mprivate\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/ls/envs/openfl_github/lib/python3.8/site-packages/openfl/experimental/interface/fl_spec.py:251\u001b[0m, in \u001b[0;36mFLSpec.next\u001b[0;34m(self, f, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     g \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, func)\n\u001b[1;32m    250\u001b[0m     \u001b[39m# remove private collaborator state\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m     g([FLSpec\u001b[39m.\u001b[39;49m_clones[col] \u001b[39mfor\u001b[39;49;00m col \u001b[39min\u001b[39;49;00m selected_collaborators])\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     to_exec \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/ls/envs/openfl_github/lib/python3.8/site-packages/openfl/experimental/placement/placement.py:48\u001b[0m, in \u001b[0;36maggregator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mwith\u001b[39;00m RedirectStdStreamContext() \u001b[39mas\u001b[39;00m context_stream:\n\u001b[1;32m     46\u001b[0m     \u001b[39m# context_stream capture stdout and stderr for the function f.__name__\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[39msetattr\u001b[39m(wrapper, \u001b[39m\"\u001b[39m\u001b[39m_stream_buffer\u001b[39m\u001b[39m\"\u001b[39m, context_stream)\n\u001b[0;32m---> 48\u001b[0m     f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn [3], line 63\u001b[0m, in \u001b[0;36mFederatedFlow.join\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAverage training loss = \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maverage_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAverage local model validation values = \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_model_accuracy\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m FedAvg([\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mmodel \u001b[39mfor\u001b[39;49;00m \u001b[39minput\u001b[39;49m \u001b[39min\u001b[39;49;00m inputs])\n\u001b[1;32m     64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m [\u001b[39minput\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs][\u001b[39m0\u001b[39m]\n\u001b[1;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend)\n",
      "Cell \u001b[0;32mIn [1], line 59\u001b[0m, in \u001b[0;36mFedAvg\u001b[0;34m(models)\u001b[0m\n\u001b[1;32m     57\u001b[0m state_dicts \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39mstate_dict() \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models]\n\u001b[1;32m     58\u001b[0m state_dict \u001b[39m=\u001b[39m new_model\u001b[39m.\u001b[39mstate_dict()\n\u001b[0;32m---> 59\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m models[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mstate_dict():\n\u001b[1;32m     60\u001b[0m     state_dict[key] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum([state[key] \u001b[39mfor\u001b[39;00m state \u001b[39min\u001b[39;00m state_dicts],axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(models)\n\u001b[1;32m     61\u001b[0m new_model\u001b[39m.\u001b[39mload_state_dict(state_dict)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Setup participants\n",
    "aggregator = Aggregator()\n",
    "aggregator.private_attributes = {}\n",
    "\n",
    "# Setup collaborators with private attributes\n",
    "collaborator_names = ['Portland']#, 'Seattle', 'Chandler','Bangalore']\n",
    "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
    "for idx, collaborator in enumerate(collaborators):\n",
    "    local_train = deepcopy(mnist_train)\n",
    "    local_test = deepcopy(mnist_test)\n",
    "    local_train.data = mnist_train.data[idx::len(collaborators)]\n",
    "    local_train.targets = mnist_train.targets[idx::len(collaborators)]\n",
    "    local_test.data = mnist_test.data[idx::len(collaborators)]\n",
    "    local_test.targets = mnist_test.targets[idx::len(collaborators)]\n",
    "    collaborator.private_attributes = {\n",
    "            'train_loader': torch.utils.data.DataLoader(local_train,batch_size=batch_size_train, shuffle=True),\n",
    "            'test_loader': torch.utils.data.DataLoader(local_test,batch_size=batch_size_train, shuffle=True)\n",
    "    }\n",
    "\n",
    "local_runtime = LocalRuntime(aggregator=aggregator, collaborators=collaborators,\n",
    "                            backend='single_process' )\n",
    "print(f'Local runtime collaborators = {local_runtime._collaborators}')\n",
    "\n",
    "model = None\n",
    "best_model = None\n",
    "optimizer = None\n",
    "top_model_accuracy = 0\n",
    "for i in range(1):\n",
    "    print(f'Starting round {i}...')\n",
    "    flflow = FederatedFlow(model,optimizer,checkpoint=True)\n",
    "    flflow.runtime = local_runtime\n",
    "    flflow.run()\n",
    "    model = flflow.model\n",
    "    optimizer = flflow.optimizer\n",
    "    aggregated_model_accuracy = flflow.aggregated_model_accuracy\n",
    "    if aggregated_model_accuracy > top_model_accuracy:\n",
    "        print(f'Accuracy improved to {aggregated_model_accuracy} for round {i}')\n",
    "        top_model_accuracy = aggregated_model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ddea757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.experimental.utilities.ui import InspectFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c82ecee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flowgraph generated at :/home/keerti/.metaflow/FederatedFlow/1669704190572687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<3>init: (31948) ERROR: UtilConnectToInteropServer:307: connect failed 2\n",
      "<3>init: (31958) ERROR: UtilConnectToInteropServer:307: connect failed 2\n",
      "<3>init: (31960) ERROR: UtilConnectToInteropServer:307: connect failed 2\n",
      "<3>init: (31962) ERROR: UtilConnectToInteropServer:307: connect failed 2\n"
     ]
    }
   ],
   "source": [
    "if flflow._checkpoint:\n",
    "    InspectFlow(flflow, flflow._run_id, show_html=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = flflow._run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Metaflow, Flow, Task, Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Metaflow()\n",
    "list(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Flow('FederatedFlow').latest_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Step(f'FederatedFlow/{run_id}/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Task(f'FederatedFlow/{run_id}/train/7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-working",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('openfl_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f7fdd4a1f621cec7a25690f8e21ae706f009fca3d4d2c40a83d34a2d1ea6938"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
